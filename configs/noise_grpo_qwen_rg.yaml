run_type: 'train'

# ==============================
# Seed Configuration
# ==============================
seed: 0

# ==============================
# Device Configuration
# ==============================
device: "cuda:0"

# ==============================
# Model Configuration
# ==============================
model:
  model_name: Qwen/Qwen2.5-0.5B
  chat_template_path: .../noisy_rl/data/templates/base_chat_template.txt
  checkpoint_path: null
  opt_checkpoint_path: null
  noise_layer: 0
  noise_scaling_factor: 0.6

# ==============================
# Training Configuration
# ==============================
train:
  base_lr: 5e-6
  epsilon: 0.2
  lr_scheduler: null
  weight_decay: 0.02
  batch_size: 1
  num_repeats_per_seq: 8
  num_grad_accum_steps: 4
  num_train_steps: 1800
  num_update_iters: 1
  mem_efficient_logits: True
  max_gen_toks: 600
  tok_sampling: True
  top_k: null
  top_p: null
  temperature: 1.0
  use_const_noise: False
  dataset: "reasoning-gym"
  dataset_config:
    task_name: 'sudoku'
    min_empty: 10
    max_empty: 40
  split: 'train'
  system_prompt_path: .../noisy_rl/data/templates/base_sys_prompt.txt

# ==============================
# Eval Dataset Configuration
# ==============================
eval:
  dataset: "reasoning-gym"
  dataset_config:
    task_name: 'sudoku'
    min_empty: 10
    max_empty: 40
  split: 'test'
  batch_size: 64
  system_prompt_path: .../noisy_rl/data/templates/base_sys_prompt.txt
  num_samples: 256

# ==============================
# Reward Configuration
# ==============================
reward_funcs:
  - score_reasoning_gym_sudoku
  - very_soft_format


# ==============================
# Logging Configuration
# ==============================
wnb:
  log: True
  project_name: "noise_sampling_grpo_rg"
checkpoint_freq: 50
